{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMiCnK2W+/hJuO6i4PPPMrH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#7.2. KoNLPy 라이브러리 소개"],"metadata":{"id":"SeEsHlzKgXnv"}},{"cell_type":"markdown","source":["##예제1)\t설치 및 확인"],"metadata":{"id":"G34EKNH2hFRg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ptn1U2OIg5G"},"outputs":[],"source":["!pip install konlpy"]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","\n","okt = Okt()\n","print(okt.morphs(\"KoNLPy를 설치하면 한국어 형태소 분석이 가능해요!\"))"],"metadata":{"id":"1Cjq3L1oIwID"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#7.2.2. 주요 형태소 분석기"],"metadata":{"id":"_HXh8pUfg-OV"}},{"cell_type":"markdown","source":["##예제2)\tOkt (Open Korea Text)"],"metadata":{"id":"mskMsIHJhOLh"}},{"cell_type":"code","source":["from konlpy.tag import Okt\n","# Okt 객체 생성\n","okt = Okt()\n","# 입력 텍스트\n","text = \"아버지가 방에 들어가신다.\"\n","# 형태소 분석\n","print('형태소 분석:\\n',okt.morphs(text))  # ['아버지', '가', '방', '에', '들어가신다']\n","# 품사 태깅\n","print('품사 태깅:\\n',okt.pos(text))  # [('아버지', 'Noun'), ('가', 'Josa'), ('방', 'Noun'), ...]\n","# 명사 추출\n","print('명사 추출:\\n',okt.nouns(text))  # ['아버지', '방']\n","# 어간 추출 (동사 원형 복원)\n","print('어간 추출:\\n',okt.morphs(text, stem=True))  # ['아버지', '가', '방', '에', '들어가다']"],"metadata":{"id":"wmrWyMmLNA8g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##예제3)\tKomoran 형태소 분석"],"metadata":{"id":"siRvMFbYhm6J"}},{"cell_type":"code","source":["from konlpy.tag import Komoran\n","\n","# Komoran 객체 생성\n","komoran = Komoran()\n","\n","# 형태소 분석\n","print('형태소 분석:\\n',komoran.morphs(text))\n","\n","# 품사 태깅\n","print('품사 태깅:\\n',komoran.pos(text))"],"metadata":{"id":"tLSt1K4lObAP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##예제4)\tHannanum 형태소 분석"],"metadata":{"id":"-0OOVqz-htmP"}},{"cell_type":"code","source":["from konlpy.tag import Hannanum\n","\n","# Hannanum 객체 생성\n","hannanum = Hannanum()\n","\n","# 형태소 분석\n","print('형태소 분석:\\n',hannanum.morphs(text))\n","\n","# 품사 태깅\n","print('품사 태깅:\\n',hannanum.pos(text))"],"metadata":{"id":"khnxH6hBPsAd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","#7.3. KoNLPy로 한국어 텍스트 전처리 단계"],"metadata":{"id":"lKOxsbxJh8ZZ"}},{"cell_type":"code","source":["# 예제 텍스트\n","text = \"*한국어 자연어 처리는 복잡하지만 흥미로운 분야입니다!.\"\n","\n","import re\n","# 텍스트 정제: 특수문자 제거\n","cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)  # 특수문자 제거\n","print(cleaned_text)"],"metadata":{"id":"wwY9CU6aViAn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from konlpy.tag import Okt  # Okt 형태소 분석기 불러오기\n","\n","okt = Okt()\n","\n","# 형태소 분석을 통한 토큰화\n","tokens = okt.morphs(cleaned_text)\n","print(tokens)"],"metadata":{"id":"LBh9SYKOVqKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 어간 추출 (동사의 원형 복원)\n","stemmed_tokens = okt.morphs(cleaned_text, stem=True)\n","print(stemmed_tokens)"],"metadata":{"id":"De-qoz10XhZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 품사 태깅\n","pos_tags = okt.pos(cleaned_text)\n","print(pos_tags)"],"metadata":{"id":"eYuxuksSYowf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 불용어 리스트\n","stop_words = ['는', '의', '이', '가', '에', '를', '입니다']\n","\n","# 불용어 제거\n","filtered_tokens = [word for word in tokens if word not in stop_words]\n","print(filtered_tokens)\n"],"metadata":{"id":"Jm1nIzGkZGAG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n","# 단어 빈도 계산\n","word_counts = Counter(filtered_tokens)\n","print(word_counts)"],"metadata":{"id":"wrEkLzdmaZQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk import ngrams\n","\n","bigrams = list(ngrams(filtered_tokens, 2))\n","print(bigrams)"],"metadata":{"id":"lrK6UkA7bl-z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##예제5)\t한국어 텍스트 전처리 단계 전체 코드"],"metadata":{"id":"MSZDGOgDZQXI"}},{"cell_type":"code","source":["import re\n","from konlpy.tag import Okt\n","from collections import Counter\n","from nltk import ngrams\n","text = \"*한국어 자연어 처리는 복잡하지만 흥미로운 분야입니다!.\" # 1. 데이터 수집\n","# 2. 텍스트 정제 (특수문자 제거)\n","cleaned_text = re.sub(r\"[^\\w\\s]\", \"\", text)\n","# 3. 토큰화\n","okt = Okt()\n","tokens = okt.morphs(cleaned_text)\n","# 4. 어간추출\n","stemmed_tokens = okt.morphs(cleaned_text, stem=True)\n","# 5. 품사 태깅\n","pos_tags = okt.pos(cleaned_text)\n","# 6. 불용어 제거\n","stop_words = ['는', '의', '이', '가', '에', '를', '입니다']\n","filtered_tokens = [word for word in tokens if word not in stop_words]\n","# 7. 단어 빈도 계산\n","word_counts = Counter(filtered_tokens)\n","# 8. N-그램 생성 함수\n","bigrams = list(ngrams(filtered_tokens, 2))\n","print(\"텍스트 정제:\", cleaned_text)\n","print(\"토큰화:\", tokens)\n","print(\"어간 추출:\", stemmed_tokens)\n","print(\"품사 태깅:\", pos_tags)\n","print(\"불용어 제거:\", filtered_tokens)\n","print(\"단어 빈도 계산:\", word_counts)\n","print(\"N-그램 생성:\", bigrams)\n"],"metadata":{"id":"a4piphsvdOhp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","#7.4. 실전 퀘스트 “잃어버린 강아지를 찾는 이야기”"],"metadata":{"id":"QAnEseB6iYyZ"}},{"cell_type":"markdown","source":["##예제6)\t“잃어버린 강아지를 찾는 이야기” 전체 코드"],"metadata":{"id":"eeX-nTD3ieUb"}},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from nltk import ngrams\n","from konlpy.tag import Okt\n","import matplotlib.pyplot as plt\n","plt.rc('font', family='NanumGothic')  # 한글 폰트 설정\n","plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호가 깨지지 않도록 설정\n","# 예제 데이터: 강아지를 찾는 SNS/블로그 게시글\n","# 한글 텍스트 데이터 준비\n","text_data = [\n","    \"강아지가 공원에서 놀다가 사라졌어요!!!\",\n","    \"어제 강아지를 산책시키다 잃어버렸습니다.\",\n","    \"공원 근처에서 비숑을 본 사람 없나요?\",\n","    \"강아지가 빨간 목줄을 하고 있어요.\",\n","    \"강아지를 찾습니다! 마지막으로 본 곳은 한강공원입니다.\",\n","    \"흰색 비숑이 시장 근처에서 돌아다니는 걸 봤어요.\",\n","    \"빨간 목줄 강아지를 시장에서 봤어요!\"\n","    \"실종된 강아지는 흰색 비숑이에요. 이름은 코코입니다.\",\n","    \"비숑이 지나가는 사람을 따라갔다는 목격 정보가 있어요.\",\n","    \"마지막으로 본 곳은 지하철역 근처입니다.\",\n","    \"강아지가 겁이 많아서 사람을 보면 도망칠 수도 있어요.\",\n","    \"한 남성이 시장에서 강아지를 데리고 가는 걸 봤다는 제보가 있어요.\",\n","    \"잃어버린 강아지는 비숑이고, 흰 털이 너무 귀여워요.^*^\",\n","    \"우리 강아지는 이름을 부르면 달려옵니다. '코코'라고 불러 주세요!\",\n","    \"빨간 목줄을 한 강아지를 찾습니다. 특징은 체구가 작은 비숑입니다.\",\n","    \"어떤 분이 SNS에 비숑같은 강아지 사진을 올렸다고 하는데, 확인할 방법이 있을까요?\",\n","    \"강아지가 강변을 따라 걸어갔을 수도 있어요. 그쪽에서 본 분 없나요?\",\n","    \"흰색 강아지가 아파트 단지에서 발견되었다는 소식을 들었어요.\",\n","    \"동네 슈퍼 근처에서 흰색 강아지를 본 것 같아요. 자세한 정보가 필요합니다.\"\n","    \"빨간 목줄을 한 흰색 비숑을 시장 옆 아파트에서 봤어요.\"\n","]\n","# 텍스트 정제 (특수문자 제거)\n","cleaned_text = [re.sub(r\"[^\\w\\s]\", \"\", sentence) for sentence in text_data]\n","# 형태소 분석기 초기화\n","okt = Okt()\n","# 형태소 분석 (단어 토큰화)\n","tokenized_text = [okt.morphs(sentence, stem=True) for sentence in cleaned_text]\n","# 리스트를 하나의 리스트로 합치기\n","flat_tokens = [word for sublist in tokenized_text for word in sublist]\n"],"metadata":{"id":"grJhguZjgOa2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 불용어 리스트 정의\n","stop_words = [\"에서\", \"하다\", \"을\", \"를\", \"이\", \"가\", \"은\", \"는\", \"에\", \"도\", \"있다\", \"없다\", \"본\", \"있는\", \"이다\", \"으로\"]\n","# 불용어 제거\n","filtered_tokens = [word for word in flat_tokens if word not in stop_words]\n","\n","# 단어 빈도 분석 (1-그램)\n","word_counts = Counter(filtered_tokens)\n","print(\"[1-그램] 단어 빈도 분석:\")\n","print(word_counts.most_common(10))  # 상위 10개 단어 출력\n","# 2-그램 (Bigram) 생성\n","bigrams = list(ngrams(filtered_tokens, 2))\n","bigram_counts = Counter(bigrams)\n","print(\"[2-그램] 단어 연관성 분석:\")\n","print(bigram_counts.most_common(10))  # 상위 10개 단어 쌍 출력\n","# 3-그램 (Trigram) 생성\n","trigrams = list(ngrams(filtered_tokens, 3))\n","trigram_counts = Counter(trigrams)\n","print(\"[3-그램] 단어 흐름 분석:\")\n","print(trigram_counts.most_common(10))  # 상위 10개 단어 조합 출력\n","\n"],"metadata":{"id":"XBdvGpqFikYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from nltk import ngrams\n","from konlpy.tag import Okt\n","\n","# 1️⃣ 영화 리뷰 데이터\n","reviews = [\n","    \"타이타닉은 정말 감동적인 영화였어요.\",\n","    \"타이타닉 배가 침몰하는 장면은 너무 슬펐어요.\",\n","    \"타이타닉은 로맨스와 드라마 요소가 강한 영화입니다.\",\n","    \"타이타닉 하면 떠오르는 건 사랑 이야기죠.\",\n","    \"잭과 로즈의 사랑이 너무 아름다웠어요.\",\n","    \"배가 침몰하는 장면에서 사람들의 절박함이 전해졌어요.\",\n","    \"영화 속 음악이 정말 감동적이었어요. 특히 My Heart Will Go On은 최고였어요.\",\n","    \"타이타닉은 실화 바탕이라 더 감명 깊었어요.\",\n","    \"영화의 비주얼과 CG가 매우 인상적이었어요.\",\n","    \"로즈와 잭의 마지막 장면은 정말 슬펐어요.\",\n","    \"타이타닉은 단순한 로맨스 영화가 아니라, 희생과 감동을 담은 작품이에요.\",\n","    \"잭이 로즈를 위해 희생하는 모습이 너무 감동적이었어요.\",\n","    \"타이타닉을 볼 때마다 눈물이 나요.\",\n","    \"배가 가라앉는 장면은 너무 현실적이었고, 공포감이 느껴졌어요.\",\n","    \"이 영화는 몇 번을 봐도 질리지 않아요.\",\n","    \"사랑, 감동, 희생이 어우러진 최고의 명작입니다.\",\n","    \"타이타닉을 보면 가슴이 먹먹해지고 여운이 오래 남아요.\",\n","    \"역사적인 사건을 아름다운 로맨스로 표현한 영화라고 생각해요.\",\n","    \"타이타닉의 영상미와 음악은 시대를 초월한 명작입니다.\",\n","    \"로즈와 잭의 사랑은 영원할 것 같아요.\"\n","]\n","\n","\n","# 2️⃣ 텍스트 정제 (특수문자 제거)\n","cleaned_reviews = [re.sub(r\"[^\\w\\s]\", \"\", review) for review in reviews]\n","\n","# 3️⃣ 형태소 분석 (Okt 사용)\n","okt = Okt()\n","tokens = [okt.morphs(review) for review in cleaned_reviews]\n","\n","# 4️⃣ 리스트를 하나의 리스트로 합치기\n","flat_tokens = [word for sublist in tokens for word in sublist]\n","\n","# 5️⃣ 불용어 제거 (예: 조사, 어미 등)\n","stop_words = [\"은\", \"는\", \"이\", \"가\", \"을\", \"를\", \"과\", \"한\", \"함께\", \"합니다\", \"했어요\"]\n","filtered_tokens = [word for word in flat_tokens if word not in stop_words]\n","\n","# 6️⃣ 단어 빈도 계산 (1-그램)\n","word_counts = Counter(filtered_tokens)\n","print(\"\\n✅ [1-그램] 단어 빈도 분석:\")\n","print(word_counts.most_common(10))  # 상위 10개 단어 출력\n","\n","# 7️⃣ 2-그램 (Bigram) 생성\n","bigrams = list(ngrams(filtered_tokens, 2))\n","bigram_counts = Counter(bigrams)\n","print(\"\\n✅ [2-그램] 단어 연관성 분석:\")\n","print(bigram_counts.most_common(10))  # 상위 10개 단어 쌍 출력\n","\n","# 8️⃣ 3-그램 (Trigram) 생성\n","trigrams = list(ngrams(filtered_tokens, 3))\n","trigram_counts = Counter(trigrams)\n","print(\"\\n✅ [3-그램] 단어 흐름 분석:\")\n","print(trigram_counts.most_common(10))  # 상위 10개 단어 조합 출력\n"],"metadata":{"id":"19llx9cfkDwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"id":"1eRCZ9Uluk2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from nltk import ngrams\n","from konlpy.tag import Okt\n","import matplotlib.pyplot as plt # 시각화\n","\n","# 1️⃣ 예제 데이터: 강아지를 찾는 SNS/블로그 게시글\n","# 한글 텍스트 데이터 준비\n","text_data = [\n","    \"강아지가 공원에서 놀다가 사라졌어요!!!\",\n","    \"어제 강아지를 산책시키다 잃어버렸습니다.\",\n","    \"공원 근처에서 비숑을 본 사람 없나요?\",\n","    \"강아지가 빨간 목줄을 하고 있어요.\",\n","    \"강아지를 찾습니다! 마지막으로 본 곳은 한강공원입니다.\",\n","    \"흰색 비숑이 시장 근처에서 돌아다니는 걸 봤어요.\",\n","    \"빨간 목줄 강아지를 시장에서 봤어요!\"\n","    \"실종된 강아지는 흰색 비숑이에요. 이름은 코코입니다.\",\n","    \"비숑이 지나가는 사람을 따라갔다는 목격 정보가 있어요.\",\n","    \"마지막으로 본 곳은 지하철역 근처입니다.\",\n","    \"강아지가 겁이 많아서 사람을 보면 도망칠 수도 있어요.\",\n","    \"한 남성이 시장에서 강아지를 데리고 가는 걸 봤다는 제보가 있어요.\",\n","    \"잃어버린 강아지는 비숑이고, 흰 털이 너무 귀여워요.^*^\",\n","    \"우리 강아지는 이름을 부르면 달려옵니다. '코코'라고 불러 주세요!\",\n","    \"빨간 목줄을 한 강아지를 찾습니다. 특징은 체구가 작은 비숑입니다.\",\n","    \"어떤 분이 SNS에 비숑같은 강아지 사진을 올렸다고 하는데, 확인할 방법이 있을까요?\",\n","    \"강아지가 강변을 따라 걸어갔을 수도 있어요. 그쪽에서 본 분 없나요?\",\n","    \"흰색 강아지가 아파트 단지에서 발견되었다는 소식을 들었어요.\",\n","    \"동네 슈퍼 근처에서 흰색 강아지를 본 것 같아요. 자세한 정보가 필요합니다.\"\n","    \"빨간 목줄을 한 흰색 비숑을 시장 옆 아파트에서 봤어요.\"\n","]\n","\n","\n","# 2️⃣ 텍스트 정제 (특수문자 제거)\n","cleaned_text = [re.sub(r\"[^\\w\\s]\", \"\", sentence) for sentence in text_data]\n","# print(cleaned_text)\n","\n","# 3️⃣ 형태소 분석기 초기화\n","okt = Okt()\n","\n","# 4️⃣ 형태소 분석 (단어 토큰화)\n","tokenized_text = [okt.morphs(sentence, stem=True) for sentence in cleaned_text]\n","\n","# 5️⃣ 리스트를 하나의 리스트로 합치기\n","flat_tokens = [word for sublist in tokenized_text for word in sublist]\n","# print(flat_tokens)\n","# 6️⃣ 불용어 리스트 정의\n","stop_words = [\"에서\", \"하다\", \"을\", \"를\", \"이\", \"가\", \"은\", \"는\", \"에\", \"도\", \"있다\", \"없다\", \"본\", \"있는\", \"이다\", \"으로\"]\n","\n","# 7️⃣ 불용어 제거\n","filtered_tokens = [word for word in flat_tokens if word not in stop_words]\n","# print(filtered_tokens)\n","\n","# 8️⃣ 단어 빈도 분석 (1-그램)\n","word_counts = Counter(filtered_tokens)\n","print(\"[1-그램] 단어 빈도 분석:\")\n","print(word_counts.most_common(10))  # 상위 10개 단어 출력\n","\n","# 9️⃣ 2-그램 (Bigram) 생성\n","bigrams = list(ngrams(filtered_tokens, 2))\n","bigram_counts = Counter(bigrams)\n","print(\"\\n[2-그램] 단어 연관성 분석:\")\n","print(bigram_counts.most_common(10))  # 상위 10개 단어 쌍 출력\n","\n","# 🔟 3-그램 (Trigram) 생성\n","trigrams = list(ngrams(filtered_tokens, 3))\n","trigram_counts = Counter(trigrams)\n","print(\"\\n[3-그램] 단어 흐름 분석:\")\n","print(trigram_counts.most_common(10))  # 상위 10개 단어 조합 출력\n"],"metadata":{"id":"EpRBlATJuB5J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#예제6)\t단어 빈도 분석 시각화 (막대 그래프)"],"metadata":{"id":"RLAe2KIESGwZ"}},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from nltk import ngrams\n","from konlpy.tag import Okt\n","import matplotlib.pyplot as plt\n","\n","plt.rc('font', family='NanumGothic')  # 한글 폰트 설정\n","plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호가 깨지지 않도록 설정\n","\n","\n","# 1️⃣ 예제 데이터: 강아지를 찾는 SNS/블로그 게시글\n","# 한글 텍스트 데이터 준비\n","text_data = [\n","    \"강아지가 공원에서 놀다가 사라졌어요!!!\",\n","    \"어제 강아지를 산책시키다 잃어버렸습니다.\",\n","    \"공원 근처에서 비숑을 본 사람 없나요?\",\n","    \"강아지가 빨간 목줄을 하고 있어요.\",\n","    \"강아지를 찾습니다! 마지막으로 본 곳은 한강공원입니다.\",\n","    \"흰색 비숑이 시장 근처에서 돌아다니는 걸 봤어요.\",\n","    \"빨간 목줄 강아지를 시장에서 봤어요!\"\n","    \"실종된 강아지는 흰색 비숑이에요. 이름은 코코입니다.\",\n","    \"비숑이 지나가는 사람을 따라갔다는 목격 정보가 있어요.\",\n","    \"마지막으로 본 곳은 지하철역 근처입니다.\",\n","    \"강아지가 겁이 많아서 사람을 보면 도망칠 수도 있어요.\",\n","    \"한 남성이 시장에서 강아지를 데리고 가는 걸 봤다는 제보가 있어요.\",\n","    \"잃어버린 강아지는 비숑이고, 흰 털이 너무 귀여워요.^*^\",\n","    \"우리 강아지는 이름을 부르면 달려옵니다. '코코'라고 불러 주세요!\",\n","    \"빨간 목줄을 한 강아지를 찾습니다. 특징은 체구가 작은 비숑입니다.\",\n","    \"어떤 분이 SNS에 비숑같은 강아지 사진을 올렸다고 하는데, 확인할 방법이 있을까요?\",\n","    \"강아지가 강변을 따라 걸어갔을 수도 있어요. 그쪽에서 본 분 없나요?\",\n","    \"흰색 강아지가 아파트 단지에서 발견되었다는 소식을 들었어요.\",\n","    \"동네 슈퍼 근처에서 흰색 강아지를 본 것 같아요. 자세한 정보가 필요합니다.\"\n","    \"빨간 목줄을 한 흰색 비숑을 시장 옆 아파트에서 봤어요.\"\n","]\n","\n","\n","# 2️⃣ 텍스트 정제 (특수문자 제거)\n","cleaned_text = [re.sub(r\"[^\\w\\s]\", \"\", sentence) for sentence in text_data]\n","# print(cleaned_text)\n","\n","# 3️⃣ 형태소 분석기 초기화\n","okt = Okt()\n","\n","# 4️⃣ 형태소 분석 (단어 토큰화)\n","tokenized_text = [okt.morphs(sentence, stem=True) for sentence in cleaned_text]\n","\n","# 5️⃣ 리스트를 하나의 리스트로 합치기\n","flat_tokens = [word for sublist in tokenized_text for word in sublist]\n","# print(flat_tokens)\n","# 6️⃣ 불용어 리스트 정의\n","stop_words = [\"에서\", \"하다\", \"을\", \"를\", \"이\", \"가\", \"은\", \"는\", \"에\", \"도\", \"있다\", \"없다\", \"본\", \"있는\", \"이다\", \"으로\"]\n","\n","# 7️⃣ 불용어 제거\n","filtered_tokens = [word for word in flat_tokens if word not in stop_words]\n","# print(filtered_tokens)\n","\n","# 8️⃣ 단어 빈도 분석 (1-그램)\n","word_counts = Counter(filtered_tokens)\n","print(\"[1-그램] 단어 빈도 분석:\")\n","print(word_counts.most_common(10))  # 상위 10개 단어 출력\n","\n","most_common_words = word_counts.most_common(10)  # 빈도수가 높은 10개 단어 추출\n","words, counts = zip(*most_common_words)  # 단어와 빈도를 각각 리스트로 분리\n","\n","# 막대 그래프 생성\n","plt.bar(words, counts, color=\"skyblue\")  # 단어별 빈도를 막대 그래프로 표현\n","plt.xlabel(\"단어\", fontsize=12)  # x축 라벨\n","plt.ylabel(\"빈도수\", fontsize=12)  # y축 라벨\n","plt.title(\"강아지 실종 관련 주요 단어 빈도 분석\", fontsize=14)  # 그래프 제목\n","plt.xticks(rotation=45)  # x축 단어 회전 (가독성 개선)\n","plt.show()\n"],"metadata":{"id":"pFlhn34nvQSN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["전체 코드"],"metadata":{"id":"I9C37jHnMJZB"}},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from nltk import ngrams\n","from konlpy.tag import Okt\n","import matplotlib.pyplot as plt\n","plt.rc('font', family='NanumGothic')  # 한글 폰트 설정\n","plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호가 깨지지 않도록 설정\n","# 1️⃣ 예제 데이터: 강아지를 찾는 SNS/블로그 게시글\n","# 한글 텍스트 데이터 준비\n","text_data = [\n","    \"강아지가 공원에서 놀다가 사라졌어요!!!\",\n","    \"어제 강아지를 산책시키다 잃어버렸습니다.\",\n","    \"공원 근처에서 비숑을 본 사람 없나요?\",\n","    \"강아지가 빨간 목줄을 하고 있어요.\",\n","    \"강아지를 찾습니다! 마지막으로 본 곳은 한강공원입니다.\",\n","    \"흰색 비숑이 시장 근처에서 돌아다니는 걸 봤어요.\",\n","    \"빨간 목줄 강아지를 시장에서 봤어요!\"\n","    \"실종된 강아지는 흰색 비숑이에요. 이름은 코코입니다.\",\n","    \"비숑이 지나가는 사람을 따라갔다는 목격 정보가 있어요.\",\n","    \"마지막으로 본 곳은 지하철역 근처입니다.\",\n","    \"강아지가 겁이 많아서 사람을 보면 도망칠 수도 있어요.\",\n","    \"한 남성이 시장에서 강아지를 데리고 가는 걸 봤다는 제보가 있어요.\",\n","    \"잃어버린 강아지는 비숑이고, 흰 털이 너무 귀여워요.^*^\",\n","    \"우리 강아지는 이름을 부르면 달려옵니다. '코코'라고 불러 주세요!\",\n","    \"빨간 목줄을 한 강아지를 찾습니다. 특징은 체구가 작은 비숑입니다.\",\n","    \"어떤 분이 SNS에 비숑같은 강아지 사진을 올렸다고 하는데, 확인할 방법이 있을까요?\",\n","    \"강아지가 강변을 따라 걸어갔을 수도 있어요. 그쪽에서 본 분 없나요?\",\n","    \"흰색 강아지가 아파트 단지에서 발견되었다는 소식을 들었어요.\",\n","    \"동네 슈퍼 근처에서 흰색 강아지를 본 것 같아요. 자세한 정보가 필요합니다.\"\n","    \"빨간 목줄을 한 흰색 비숑을 시장 옆 아파트에서 봤어요.\"\n","]\n","# 2️⃣ 텍스트 정제 (특수문자 제거)\n","cleaned_text = [re.sub(r\"[^\\w\\s]\", \"\", sentence) for sentence in text_data]\n","# print(cleaned_text)\n","# 3️⃣ 형태소 분석기 초기화\n","okt = Okt()\n","# 4️⃣ 형태소 분석 (단어 토큰화)\n","tokenized_text = [okt.morphs(sentence, stem=True) for sentence in cleaned_text]\n","# 5️⃣ 리스트를 하나의 리스트로 합치기\n","flat_tokens = [word for sublist in tokenized_text for word in sublist]\n","# print(flat_tokens)\n","# 6️⃣ 불용어 리스트 정의\n","stop_words = [\"에서\", \"하다\", \"을\", \"를\", \"이\", \"가\", \"은\", \"는\", \"에\", \"도\", \"있다\", \"없다\", \"본\", \"있는\", \"이다\", \"으로\"]\n","# 7️⃣ 불용어 제거\n","filtered_tokens = [word for word in flat_tokens if word not in stop_words]\n","# print(filtered_tokens)\n","\n","# 8️⃣ 단어 빈도 분석 (1-그램)\n","word_counts = Counter(filtered_tokens)\n","print(word_counts)\n","print(\"---\"*10)\n","print(\"[1-그램] 단어 빈도 분석:\")\n","print(word_counts.most_common(10))  # 상위 10개 단어 출력\n","word_freq = dict(word_counts)\n","print(word_freq)\n","# # 9️⃣ 2-그램 (Bigram) 생성\n","# bigrams = list(ngrams(filtered_tokens, 2))\n","# bigram_counts = Counter(bigrams)\n","# print(\"\\n[2-그램] 단어 연관성 분석:\")\n","# print(bigram_counts.most_common(10))  # 상위 10개 단어 쌍 출력\n","# # 🔟 3-그램 (Trigram) 생성\n","# trigrams = list(ngrams(filtered_tokens, 3))\n","# trigram_counts = Counter(trigrams)\n","# print(\"\\n[3-그램] 단어 흐름 분석:\")\n","# print(trigram_counts.most_common(10))  # 상위 10개 단어 조합 출력\n","# most_common_words = word_counts.most_common(10)  # 빈도수가 높은 10개 단어 추출\n","# words, counts = zip(*most_common_words)  # 단어와 빈도를 각각 리스트로 분리\n","# # 막대 그래프 생성\n","# plt.bar(words, counts, color=\"skyblue\")  # 단어별 빈도를 막대 그래프로 표현\n","# plt.xlabel(\"단어\", fontsize=12)  # x축 라벨\n","# plt.ylabel(\"빈도수\", fontsize=12)  # y축 라벨\n","# plt.title(\"강아지 실종 관련 주요 단어 빈도 분석\", fontsize=14)  # 그래프 제목\n","# plt.xticks(rotation=45)  # x축 단어 회전 (가독성 개선)\n","# plt.show()\n"],"metadata":{"id":"suI8j0AKMIns"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","from collections import Counter\n","from nltk import ngrams\n","from konlpy.tag import Okt\n","text_data = [\n","    \"강아지가 공원에서 놀다가 사라졌어요!!!\",\n","    \"어제 강아지를 산책시키다 잃어버렸습니다.\",\n","    \"공원 근처에서 강아지 본 사람 없나요?\",\n","    \"강아지가 빨간 목줄을 하고 있어요.\",\n","    \"강아지를 찾습니다! 마지막으로 본 곳은 한강공원입니다.\",\n","    \"강아지가 시장 근처에서 돌아다니는 걸 봤어요.\",\n","    \"실종된 강아지는 흰색 푸들이에요. 이름은 코코입니다.\",\n","    \"강아지가 지나가는 사람을 따라갔다는 목격 정보가 있어요.\",\n","    \"어제 오후 3시쯤 산책하던 강아지를 놓쳤어요. 도와주세요!\",\n","    \"마지막으로 본 곳은 지하철역 근처입니다.\",\n","    \"강아지가 비 오는 날 사라졌어요. 혹시 발견하신 분 계신가요?\",\n","    \"강아지가 겁이 많아서 사람을 보면 도망칠 수도 있어요.\",\n","    \"한 남성이 강아지를 데리고 가는 걸 봤다는 제보가 있어요.\",\n","    \"잃어버린 강아지는 갈색 포메라니안이고, 귀가 쫑긋 서 있어요.\",\n","    \"우리 강아지는 이름을 부르면 달려옵니다. '코코'라고 불러 주세요!\",\n","    \"강아지를 찾습니다. 특징은 작은 체구에 꼬리가 말려 있습니다.\",\n","    \"어떤 분이 SNS에 강아지 사진을 올렸다고 하는데, 확인할 방법이 있을까요?\",\n","    \"강아지가 강변을 따라 걸어갔을 수도 있어요. 그쪽에서 본 분 없나요?\",\n","    \"강아지가 아파트 단지에서 발견되었다는 소식을 들었어요.\",\n","    \"동네 슈퍼 근처에서 강아지를 본 것 같아요. 자세한 정보가 필요합니다.\"\n","]\n","cleaned_text = [re.sub(r\"[^\\w\\s]\", \"\", sentence) for sentence in text_data]\n","okt = Okt()\n","tokenized_text = [okt.morphs(sentence, stem=True) for sentence in cleaned_text]\n","flat_tokens = [word for sublist in tokenized_text for word in sublist]\n","stop_words = [\"에서\", \"하다\", \"을\", \"를\", \"이\", \"가\", \"은\", \"는\", \"에\", \"도\", \"있다\", \"없다\", \"본\", \"있는\", \"이다\"]\n","filtered_tokens = [word for word in flat_tokens if word not in stop_words]\n","word_counts = Counter(filtered_tokens)\n","print(\"\\n✅ [1-그램] 단어 빈도 분석:\")\n","print(word_counts.most_common(10))  # 상위 10개 단어 출력\n","bigrams = list(ngrams(filtered_tokens, 2))\n","bigram_counts = Counter(bigrams)\n","print(\"\\n✅ [2-그램] 단어 연관성 분석:\")\n","print(bigram_counts.most_common(10))  # 상위 10개 단어 쌍 출력\n","trigrams = list(ngrams(filtered_tokens, 3))\n","trigram_counts = Counter(trigrams)\n","print(\"\\n✅ [3-그램] 단어 흐름 분석:\")\n","print(trigram_counts.most_common(10))  # 상위 10개 단어 조합 출력\n","\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n","# 단어 빈도 데이터 준비\n","word_freq = dict(word_counts)\n","# 워드 클라우드 생성\n","wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n","# 시각화\n","plt.imshow(wordcloud, interpolation=\"bilinear\")\n","plt.axis(\"off\")  # 축 제거\n","plt.title(\"강아지 실종 관련 주요 단어\", fontsize=16)\n","plt.show()\n","\n"],"metadata":{"id":"lVW_Cjv53Un5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import networkx as nx\n","import matplotlib.pyplot as plt # Import the matplotlib.pyplot module\n","\n","# 1️⃣ 네트워크 그래프 초기화\n","G = nx.Graph()\n","\n","# 2️⃣ 상위 15개의 2-그램(연관 단어 쌍) 추가\n","for (word1, word2), freq in bigram_counts.most_common(15):\n","    G.add_edge(word1, word2, weight=freq)\n","\n","# 3️⃣ 그래프 시각화\n","plt.figure(figsize=(10, 6))\n","pos = nx.spring_layout(G, seed=42)  # 노드 배치\n","nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"lightblue\", font_size=12, edge_color=\"gray\", width=2)\n","plt.title(\"강아지 실종 관련 연관 단어 네트워크\", fontsize=16)\n","plt.show()"],"metadata":{"id":"RYOY0_2Kypt1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!apt-get update\n","!apt-get install -y fonts-nanum\n","!fc-cache -fv\n","!rm ~/.cache/matplotlib -rf"],"metadata":{"id":"9rYjOGOP33Ae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install the NanumGothic font\n","!apt-get update && apt-get install -y fonts-nanum"],"metadata":{"id":"Dmm1B_-d-rSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n","# 단어 빈도 데이터 준비\n","word_freq = dict(word_counts)\n","# 워드 클라우드 생성\n","wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n","# 시각화\n","plt.imshow(wordcloud, interpolation=\"bilinear\")\n","plt.axis(\"off\")  # 축 제거\n","plt.title(\"강아지 실종 관련 주요 단어\", fontsize=16)\n","plt.show()\n"],"metadata":{"id":"RyOsuxbE3xki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.rc('font', family='NanumBarunGothic')  # 또는 'NanumGothic' 사용 가능\n","plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호가 깨지지 않도록 설정\n","\n","most_common_words = word_counts.most_common(10)  # 빈도수가 높은 10개 단어 추출\n","words, counts = zip(*most_common_words)  # 단어와 빈도를 각각 리스트로 분리\n","# 막대 그래프 생성\n","plt.bar(words, counts, color=\"skyblue\")  # 단어별 빈도를 막대 그래프로 표현\n","plt.xlabel(\"단어\", fontsize=12)  # x축 라벨\n","plt.ylabel(\"빈도수\", fontsize=12)  # y축 라벨\n","plt.title(\"강아지 실종 관련 주요 단어 빈도 분석\", fontsize=14)  # 그래프 제목\n","plt.xticks(rotation=45)  # x축 단어 회전 (가독성 개선)\n","plt.show()\n"],"metadata":{"id":"-dy7Txo540sP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","# 한글 폰트 설정 (NanumBarunGothic 또는 NanumGothic 사용 가능)\n","plt.rc('font', family='NanumGothic')\n","plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지\n","\n","# 샘플 데이터 (예제)\n","sample_text = [\"강아지\", \"실종\", \"찾기\", \"강아지\", \"보호\", \"강아지\", \"신고\", \"실종\", \"신고\", \"보호\", \"보호\", \"실종\", \"강아지\", \"강아지\", \"강아지\"]\n","word_counts = Counter(sample_text)  # 단어 빈도수 계산\n","\n","# 빈도수가 높은 10개 단어 추출\n","most_common_words = word_counts.most_common(10)\n","words, counts = zip(*most_common_words)  # 단어와 빈도를 각각 리스트로 분리\n","\n","# 막대 그래프 생성\n","plt.figure(figsize=(10, 6))  # 그래프 크기 설정\n","plt.bar(words, counts, color=\"skyblue\")  # 단어별 빈도를 막대 그래프로 표현\n","plt.xlabel(\"단어\", fontsize=12)  # x축 라벨\n","plt.ylabel(\"빈도수\", fontsize=12)  # y축 라벨\n","plt.title(\"강아지 실종 관련 주요 단어 빈도 분석\", fontsize=14)  # 그래프 제목\n","plt.xticks(rotation=45)  # x축 단어 회전 (가독성 개선)\n","plt.grid(axis='y', linestyle='--', alpha=0.7)  # 가독성을 위한 격자 추가\n","plt.show()\n"],"metadata":{"id":"a_7_qAoTA3PH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n","# 단어 빈도 데이터 준비\n","word_freq = dict(word_counts)\n","# 워드 클라우드 생성\n","wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n","# 시각화\n","plt.imshow(wordcloud, interpolation=\"bilinear\")\n","plt.axis(\"off\")  # 축 제거\n","plt.title(\"강아지 실종 관련 주요 단어\", fontsize=16)\n","plt.show()\n"],"metadata":{"id":"5NamF3KOFDH6"},"execution_count":null,"outputs":[]}]}