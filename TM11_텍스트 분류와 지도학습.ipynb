{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMJicT1bu8ZE+QG835X7SOg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-6Hmt-V0m8Ky"},"outputs":[],"source":["import pandas as pd  # ë°ì´í„° ì²˜ë¦¬\n","from sklearn.feature_extraction.text import CountVectorizer  # í…ìŠ¤íŠ¸ ë²¡í„°í™”\n","from sklearn.model_selection import train_test_split  # ë°ì´í„° ë‚˜ëˆ„ê¸°\n","from sklearn.naive_bayes import MultinomialNB  # ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸\n","from sklearn.metrics import accuracy_score  # ëª¨ë¸ í‰ê°€\n"]},{"cell_type":"code","source":["# ì˜í™” ë¦¬ë·° ë°ì´í„° ì¤€ë¹„\n","data = {'review': [\n","    \"ì´ ì˜í™” ë„ˆë¬´ ê°ë™ì ì´ê³  ì¬ë¯¸ìˆì—ˆì–´ìš”\",  # ê¸ì •\n","    \"ì™„ì „ ë³„ë¡œì˜€ì–´ìš”. ëˆì´ ì•„ê¹Œì›€\",  # ë¶€ì •\n","    \"ìµœê³ ì˜ ì˜í™”ì…ë‹ˆë‹¤! ë˜ ë³´ê³  ì‹¶ì–´ìš”\",  # ê¸ì •\n","    \"ë‹¤ì‹œëŠ” ì•ˆ ë³´ê³  ì‹¶ì–´ìš”. ì§€ë£¨í•´ìš”\",  # ë¶€ì •\n","    \"ì •ë§ ë©‹ì§„ ì‘í’ˆì…ë‹ˆë‹¤. ê°•ì¶”!\",  # ê¸ì •\n","    \"ì‹œê°„ ë‚­ë¹„ì˜€ì–´ìš”. ì‹¤ë§ìŠ¤ëŸ¬ì›€\"  # ë¶€ì •\n","],\n","'label': [1, 0, 1, 0, 1, 0]}  # 1: ê¸ì •, 0: ë¶€ì •\n","\n","# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n","df = pd.DataFrame(data)\n","\n","# ë°ì´í„° í™•ì¸\n","print(df)\n","df\n"],"metadata":{"id":"lH4aCJPZnnj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë²¡í„°í™” ê³¼ì •\n","vectorizer = CountVectorizer()  # ë‹¨ì–´ ë¹ˆë„ìˆ˜ ê¸°ë°˜ ë²¡í„°í™”\n","X_vectorized = vectorizer.fit_transform(df['review'])  # í…ìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜\n","# ë²¡í„°í™”ëœ ë°ì´í„° í™•ì¸ (ìˆ«ìë¡œ ë³€í™˜ë¨)\n","print(X_vectorized.toarray())\n"],"metadata":{"id":"B6EE0YK_oADe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‚˜ëˆ„ê¸°\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, df['label'], test_size=0.2, random_state=42)\n","\n","# ë°ì´í„° ê°œìˆ˜ í™•ì¸\n","print(f\"í•™ìŠµ ë°ì´í„° ê°œìˆ˜: {X_train.shape[0]}, í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜: {X_test.shape[0]}\") # Use shape[0] to get the number of rows"],"metadata":{"id":"VfTnKMkQo4Qb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","# ëª¨ë¸ ì˜ˆì¸¡\n","y_pred = model.predict(X_test)\n","\n","# ì •í™•ë„ í‰ê°€\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"ëª¨ë¸ ì •í™•ë„: {accuracy * 100:.2f}%\")"],"metadata":{"id":"UkSLY20dpWXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ìƒˆë¡œìš´ ë¦¬ë·° ì˜ˆì¸¡\n","new_review = [\"ì •ë§ ê°ë™ì ì¸ ì˜í™”ì˜€ì–´ìš”. ëˆˆë¬¼ì´ ë‚¬ì–´ìš”.\"]  # ì˜ˆì¸¡í•  ë¬¸ì¥\n","\n","# ë²¡í„°í™”\n","new_review_vectorized = vectorizer.transform(new_review)\n","\n","# ì˜ˆì¸¡ ìˆ˜í–‰\n","prediction = model.predict(new_review_vectorized)\n","\n","# ê²°ê³¼ ì¶œë ¥\n","result = \"ê¸ì •ì  ë¦¬ë·° ğŸ˜€\" if prediction[0] == 1 else \"ë¶€ì •ì  ë¦¬ë·° ğŸ˜¡\"\n","print(f\"ì…ë ¥ëœ ë¬¸ì¥: {new_review[0]}\")\n","print(f\"ì˜ˆì¸¡ ê²°ê³¼: {result}\")\n"],"metadata":{"id":"8eHCZ6UeqCU9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_reviews = [\"ë„ˆë¬´ ì§€ë£¨í•´ì„œ ì ë“¤ì—ˆì–´ìš”.\", \"ë°°ìš° ì—°ê¸°ê°€ ìµœê³ ì˜€ì–´ìš”!\", \"ì´ê²Œ ì˜í™”ëƒ?\", \"ëˆì´ ì•„ê¹ë‹¤.\"]\n","new_reviews_vectorized = vectorizer.transform(new_reviews)\n","predictions = model.predict(new_reviews_vectorized)\n","for review, pred in zip(new_reviews, predictions):\n","    result = \"ê¸ì •ì  ë¦¬ë·° ğŸ˜€\" if pred == 1 else \"ë¶€ì •ì  ë¦¬ë·° ğŸ˜¡\"\n","    print(f\"'{review}' â†’ ì˜ˆì¸¡ ê²°ê³¼: {result}\")\n"],"metadata":{"id":"WEY-KemeqQi0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ğŸ“Œ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n","import pandas as pd  # ë°ì´í„° ì²˜ë¦¬\n","from sklearn.feature_extraction.text import CountVectorizer  # í…ìŠ¤íŠ¸ ë²¡í„°í™”\n","from sklearn.model_selection import train_test_split  # ë°ì´í„° ë‚˜ëˆ„ê¸°\n","from sklearn.naive_bayes import MultinomialNB  # ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜ê¸°\n","from sklearn.metrics import accuracy_score  # ëª¨ë¸ í‰ê°€\n","\n","# ğŸ“Œ 2. ì˜í™” ë¦¬ë·° ë°ì´í„° ì¤€ë¹„ (ê¸ì •=1, ë¶€ì •=0)\n","# ë°ì´í„° í™•ëŒ€ (ê¸ì •=1, ë¶€ì •=0)\n","data = {'review': [\n","    \"ì´ ì˜í™” ì •ë§ ì¬ë¯¸ìˆì–´ìš”\",  # ê¸ì •\n","    \"ì™„ì „ ë³„ë¡œì˜€ì–´ìš”\",  # ë¶€ì •\n","    \"ì •ë§ ê°ë™ì ì¸ ì´ì•¼ê¸°ì˜€ìŠµë‹ˆë‹¤\",  # ê¸ì •\n","    \"ì‹œê°„ ë‚­ë¹„ì˜€ì–´ìš”\",  # ë¶€ì •\n","    \"ìµœê³ ì˜ ì˜í™”ì˜ˆìš”\",  # ê¸ì •\n","    \"ì§€ë£¨í•´ì„œ ì¡¸ì•˜ì–´ìš”\",  # ë¶€ì •\n","    \"ì •ë§ ìµœê³ ì˜ ì‘í’ˆì´ë„¤ìš”!\",  # ê¸ì •\n","    \"ìŠ¤í† ë¦¬ê°€ ë„ˆë¬´ ì§€ë£¨í•˜ê³  ì¬ë¯¸ì—†ì–´ìš”\",  # ë¶€ì •\n","    \"ë°°ìš° ì—°ê¸°ê°€ ë›°ì–´ë‚˜ê³  ê°ë™ì ì´ì—ˆì–´ìš”\",  # ê¸ì •\n","    \"ì•¡ì…˜ì´ ë„ˆë¬´ ì§€ë£¨í•˜ê³  ê¸°ëŒ€ ì´í•˜ì˜€ìŠµë‹ˆë‹¤\",  # ë¶€ì •\n","    \"ê°€ì¡±ê³¼ í•¨ê»˜ ë³´ê¸° ì¢‹ì€ ê°ë™ì ì¸ ì˜í™”\",  # ê¸ì •\n","    \"ë„ˆë¬´ ìœ ì¹˜í•˜ê³  ë»”í•œ ë‚´ìš©\",  # ë¶€ì •\n","    \"ëˆˆë¬¼ì´ ë‚  ì •ë„ë¡œ ê°ë™ì ì´ì—ˆì–´ìš”\",  # ê¸ì •\n","    \"ë°°ìš°ë“¤ ì—°ê¸°ê°€ ë„ˆë¬´ ì–´ìƒ‰í•˜ê³  ì‹¤ë§\",  # ë¶€ì •\n","    \"ê¸°ëŒ€ ì´ìƒìœ¼ë¡œ ì¬ë¯¸ìˆê³  ê°ë™ì ì´ì—ˆì–´ìš”\",  # ê¸ì •\n","    \"ì´ê²Œ ì˜í™”ëƒ? ëˆì´ ì•„ê¹ë‹¤\",  # ë¶€ì •\n","    \"ì™„ì „ ì¶”ì²œí•©ë‹ˆë‹¤! ìµœê³ ì˜ ê°ë™ì„ ì¤¬ì–´ìš”\",  # ê¸ì •\n","    \"ë³´ëŠ” ë‚´ë‚´ ì§€ë£¨í•´ì„œ í˜ë“¤ì—ˆì–´ìš”\",  # ë¶€ì •\n","    \"ì •ë§ ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ì˜í™”ì˜€ìŠµë‹ˆë‹¤\",  # ê¸ì •\n","    \"ë„ˆë¬´ ì§€ë£¨í•´ì„œ ì¤‘ê°„ì— ë‚˜ì™”ì–´ìš”\"  # ë¶€ì •\n","],\n","'label': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]}  # 1: ê¸ì •, 0: ë¶€ì •\n","\n","# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n","df = pd.DataFrame(data)\n","\n","\n","# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n","df = pd.DataFrame(data)\n","\n","# ğŸ“Œ 3. í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜ (ë²¡í„°í™”)\n","vectorizer = CountVectorizer()  # ë‹¨ì–´ ë¹ˆë„ìˆ˜ ê¸°ë°˜ ë²¡í„°í™”\n","X_vectorized = vectorizer.fit_transform(df['review'])  # í…ìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜\n","print(X_vectorized.toarray())\n","# ğŸ“Œ 4. í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‚˜ëˆ„ê¸°\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, df['label'], test_size=0.2, random_state=42)\n","\n","\n","# ğŸ“Œ 5. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","\n","# ğŸ“Œ 6. ëª¨ë¸ ì˜ˆì¸¡ ë° ì •í™•ë„ í‰ê°€\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"ëª¨ë¸ ì •í™•ë„: {accuracy * 100:.2f}%\")\n","\n","# ğŸ“Œ 7. ìƒˆë¡œìš´ ë¦¬ë·° ì˜ˆì¸¡í•˜ê¸°\n","new_reviews = [\"ì •ë§ ê°ë™ì ì¸ ì˜í™”ì˜€ì–´ìš”. ëˆˆë¬¼ì´ ë‚¬ì–´ìš”.\", \"ë„ˆë¬´ ì§€ë£¨í•´ì„œ ì ë“¤ì—ˆì–´ìš”.\", \"ë°°ìš° ì—°ê¸°ê°€ ìµœê³ ì˜€ì–´ìš”!\"]\n","new_reviews_vectorized = vectorizer.transform(new_reviews)\n","predictions = model.predict(new_reviews_vectorized)\n","\n","# ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n","for review, pred in zip(new_reviews, predictions):\n","    result = \"ê¸ì •ì  ë¦¬ë·° ğŸ˜€\" if pred == 1 else \"ë¶€ì •ì  ë¦¬ë·° ğŸ˜¡\"\n","    print(f\"'{review}' â†’ ì˜ˆì¸¡ ê²°ê³¼: {result}\")\n"],"metadata":{"id":"LBn1DVlYqyOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ğŸ“Œ 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n","import pandas as pd  # ë°ì´í„° ì²˜ë¦¬\n","from sklearn.feature_extraction.text import TfidfVectorizer  # í…ìŠ¤íŠ¸ ë²¡í„°í™”\n","from sklearn.model_selection import train_test_split  # ë°ì´í„° ë‚˜ëˆ„ê¸°\n","from sklearn.naive_bayes import MultinomialNB  # ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸\n","from sklearn.metrics import accuracy_score  # ëª¨ë¸ í‰ê°€\n","\n","# ğŸ“Œ 3. ë¯¼ì› ë°ì´í„° ì¤€ë¹„ (ìƒ˜í”Œ ë°ì´í„°)\n","data = {\n","    \"ë¯¼ì› ì œëª©\": [\n","        \"ë„ë¡œì— ê°€ë¡œë“±ì´ ê³ ì¥ë‚¬ì–´ìš”\",\n","        \"ì“°ë ˆê¸° ë¬´ë‹¨ íˆ¬ê¸° ì‹ ê³ í•©ë‹ˆë‹¤\",\n","        \"ë…¸ì¸ ë³µì§€ í˜œíƒì„ ëŠ˜ë ¤ì£¼ì„¸ìš”\",\n","        \"íš¡ë‹¨ë³´ë„ì— ì‹ í˜¸ë“±ì´ ê³ ì¥ë‚¬ì–´ìš”\",\n","        \"ê³µì›ì— ì“°ë ˆê¸°ê°€ ë§ì•„ìš”\",\n","        \"ëŒ€ì¤‘êµí†µ ë°°ì°¨ ê°„ê²©ì´ ë„ˆë¬´ ê¸¸ì–´ìš”\",\n","        \"ê³µì›ì— ë‚˜ë¬´ê°€ ë„ˆë¬´ ìš°ê±°ì¡Œì–´ìš”\",\n","        \"ë³µì§€ê´€ í”„ë¡œê·¸ë¨ì„ í™•ëŒ€í•´ ì£¼ì„¸ìš”\"\n","    ],\n","    \"ë¯¼ì› ë‚´ìš©\": [\n","        \"ìš°ë¦¬ ë™ë„¤ ê°€ë¡œë“±ì´ êº¼ì ¸ìˆì–´ ë°¤ì— ë„ˆë¬´ ì–´ë‘ì›Œìš”.\",\n","        \"ì•„íŒŒíŠ¸ ë’¤í¸ì— ì“°ë ˆê¸°ë¥¼ ì•„ë¬´ë°ë‚˜ ë²„ë¦¬ëŠ” ì‚¬ëŒë“¤ì´ ë§ìŠµë‹ˆë‹¤.\",\n","        \"ë…¸ì¸ë“¤ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ë³µì§€ í˜œíƒì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\",\n","        \"íš¡ë‹¨ë³´ë„ ì‹ í˜¸ë“±ì´ ì‘ë™í•˜ì§€ ì•Šì•„ ì‚¬ê³  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.\",\n","        \"ê³µì› ê³³ê³³ì— ì“°ë ˆê¸°ê°€ ë°©ì¹˜ë˜ì–´ ìˆì–´ ë¶ˆí¸í•©ë‹ˆë‹¤.\",\n","        \"ë²„ìŠ¤ë¥¼ ë„ˆë¬´ ì˜¤ë˜ ê¸°ë‹¤ë ¤ì•¼ í•´ìš”.\",\n","        \"ê³µì›ì— ë‚˜ë¬´ê°€ ë„ˆë¬´ ë§ì•„ ì‹œì•¼ë¥¼ ê°€ë¦½ë‹ˆë‹¤.\",\n","        \"ë³µì§€ê´€ì—ì„œ ìš´ì˜í•˜ëŠ” í”„ë¡œê·¸ë¨ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\"\n","    ],\n","    \"ì¹´í…Œê³ ë¦¬\": [\"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"í™˜ê²½\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\"]\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# ğŸ“Œ 4. í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜ (TF-IDF ë²¡í„°í™”)\n","vectorizer = TfidfVectorizer()\n","X_vectorized = vectorizer.fit_transform(df[\"ë¯¼ì› ë‚´ìš©\"])  # 'ë¯¼ì› ë‚´ìš©'ì„ ìˆ«ìë¡œ ë³€í™˜\n","\n","# ğŸ“Œ 5. í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‚˜ëˆ„ê¸° (80% í•™ìŠµ, 20% í…ŒìŠ¤íŠ¸)\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, df[\"ì¹´í…Œê³ ë¦¬\"], test_size=0.2, random_state=42)\n","\n","# ğŸ“Œ 6. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","\n","# ğŸ“Œ 7. ëª¨ë¸ ì˜ˆì¸¡ ë° í‰ê°€\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"ëª¨ë¸ ì •í™•ë„: {accuracy * 100:.2f}%\")\n","\n","# ğŸ“Œ 8. ìƒˆë¡œìš´ ë¯¼ì› ì˜ˆì¸¡í•˜ê¸°\n","new_complaints = [\n","    \"ì§€í•˜ì² ì´ ë„ˆë¬´ ìì£¼ ê³ ì¥ë‚˜ìš”.\",\n","    \"ê³µì›ì—ì„œ ë‹´ë°°ë¥¼ í”¼ìš°ëŠ” ì‚¬ëŒì´ ë§ì•„ìš”.\",\n","    \"ë³µì§€ ì§€ì›ê¸ˆì„ ëŠ˜ë ¤ ì£¼ì„¸ìš”.\"\n","]\n","\n","new_complaints_vectorized = vectorizer.transform(new_complaints)\n","predictions = model.predict(new_complaints_vectorized)\n","\n","# ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n","for complaint, pred in zip(new_complaints, predictions):\n","    print(f\"'{complaint}' â†’ ì˜ˆì¸¡ ê²°ê³¼: {pred}\")\n"],"metadata":{"id":"iANzapXTyyhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# ìƒ˜í”Œ ë¯¼ì› ë°ì´í„° ìƒì„±\n","data = {\n","    \"ë¯¼ì› ì œëª©\": [\n","        \"ë„ë¡œì— ê°€ë¡œë“±ì´ ê³ ì¥ë‚¬ì–´ìš”\",\n","        \"ì“°ë ˆê¸° ë¬´ë‹¨ íˆ¬ê¸° ì‹ ê³ í•©ë‹ˆë‹¤\",\n","        \"ë…¸ì¸ ë³µì§€ í˜œíƒì„ ëŠ˜ë ¤ì£¼ì„¸ìš”\",\n","        \"íš¡ë‹¨ë³´ë„ì— ì‹ í˜¸ë“±ì´ ê³ ì¥ë‚¬ì–´ìš”\",\n","        \"ê³µì›ì— ì“°ë ˆê¸°ê°€ ë§ì•„ìš”\"\n","    ],\n","    \"ë¯¼ì› ë‚´ìš©\": [\n","        \"ìš°ë¦¬ ë™ë„¤ ê°€ë¡œë“±ì´ êº¼ì ¸ìˆì–´ ë°¤ì— ë„ˆë¬´ ì–´ë‘ì›Œìš”.\",\n","        \"ì•„íŒŒíŠ¸ ë’¤í¸ì— ì“°ë ˆê¸°ë¥¼ ì•„ë¬´ë°ë‚˜ ë²„ë¦¬ëŠ” ì‚¬ëŒë“¤ì´ ë§ìŠµë‹ˆë‹¤.\",\n","        \"ë…¸ì¸ë“¤ì´ ë°›ì„ ìˆ˜ ìˆëŠ” ë³µì§€ í˜œíƒì´ ë¶€ì¡±í•©ë‹ˆë‹¤.\",\n","        \"íš¡ë‹¨ë³´ë„ ì‹ í˜¸ë“±ì´ ì‘ë™í•˜ì§€ ì•Šì•„ ì‚¬ê³  ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.\",\n","        \"ê³µì› ê³³ê³³ì— ì“°ë ˆê¸°ê°€ ë°©ì¹˜ë˜ì–´ ìˆì–´ ë¶ˆí¸í•©ë‹ˆë‹¤.\"\n","    ],\n","    \"ì¹´í…Œê³ ë¦¬\": [\"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"í™˜ê²½\"]\n","}\n","\n","df = pd.DataFrame(data)\n","print(df)"],"metadata":{"id":"GdioLFgI4fyG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# ë¯¼ì› ì œëª©ê³¼ ë‚´ìš©ì„ í•©ì³ì„œ ì‚¬ìš©\n","df[\"í…ìŠ¤íŠ¸\"] = df[\"ë¯¼ì› ì œëª©\"] + \" \" + df[\"ë¯¼ì› ë‚´ìš©\"]\n","\n","# í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë²¡í„°í™”\n","vectorizer = CountVectorizer(stop_words=\"english\")\n","X = vectorizer.fit_transform(df[\"í…ìŠ¤íŠ¸\"])\n","\n","# ì¹´í…Œê³ ë¦¬ë¥¼ ìˆ«ìë¡œ ë³€í™˜\n","from sklearn.preprocessing import LabelEncoder\n","encoder = LabelEncoder()\n","y = encoder.fit_transform(df[\"ì¹´í…Œê³ ë¦¬\"])\n","\n","# ë²¡í„°í™”ëœ ë°ì´í„°ì™€ ë ˆì´ë¸” í™•ì¸\n","print(\"ë‹¨ì–´ ë²¡í„°í™” ê²°ê³¼:\")\n","print(X.toarray())\n","print(\"ë ˆì´ë¸”:\")\n","print(y)"],"metadata":{"id":"8fAITRHI4gqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","\n","# í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„ë¦¬\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ëª¨ë¸ í•™ìŠµ\n","model = MultinomialNB()\n","model.fit(X_train, y_train)"],"metadata":{"id":"DHo2V9Bg4puV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n","y_pred = model.predict(X_test)\n","\n","# Get unique labels from y_test and y_pred\n","unique_labels = sorted(list(set(y_test) | set(y_pred)))\n","\n","# ê²°ê³¼ í‰ê°€\n","print(\"ëª¨ë¸ ì„±ëŠ¥ í‰ê°€:\")\n","print(classification_report(y_test, y_pred, target_names=encoder.classes_[unique_labels])) # Only use target names for the present labels"],"metadata":{"id":"LzGW-_dM4sGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ìƒˆë¡œìš´ ë¯¼ì› ë°ì´í„°\n","new_data = [\"ë™ë„¤ ì‹ í˜¸ë“±ì´ ê³ ì¥ë‚¬ì–´ìš”.\", \"ê³µì›ì— ì“°ë ˆê¸°ê°€ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.\"]\n","new_vector = vectorizer.transform(new_data)\n","\n","# ì˜ˆì¸¡\n","new_pred = model.predict(new_vector)\n","predicted_categories = encoder.inverse_transform(new_pred)\n","\n","# ê²°ê³¼ ì¶œë ¥\n","for text, category in zip(new_data, predicted_categories):\n","    print(f\"ë¯¼ì›: '{text}' -> ì˜ˆì¸¡ëœ ì¹´í…Œê³ ë¦¬: '{category}'\")"],"metadata":{"id":"h1CnQDRs4zvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ğŸ“Œ 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# ğŸ“Œ 3. ì˜ì–´ ë°ì´í„°ì…‹ (ë¯¼ì› ë°ì´í„° ì˜ì–´ ë³€í™˜)\n","data = {\n","    \"Complaint\": [\n","        \"The streetlight is broken\",  # Traffic\n","        \"Illegal trash dumping reported\",  # Environment\n","        \"Increase welfare benefits for seniors\",  # Welfare\n","        \"Traffic signal is not working\",  # Traffic\n","        \"There is too much trash in the park\",  # Environment\n","        \"Bus intervals are too long\",  # Traffic\n","        \"Trees in the park are too dense\",  # Environment\n","        \"Expand programs in the welfare center\",  # Welfare\n","        \"The road is too bumpy to drive\",  # Traffic\n","        \"Subway breaks down too often\",  # Traffic\n","        \"Many people smoke in the park\",  # Environment\n","        \"Need more daycare facilities\",  # Welfare\n","        \"Traffic signal is too short\",  # Traffic\n","        \"Bus stop is too far away\",  # Traffic\n","        \"Strengthen environmental protection policies\",  # Environment\n","        \"Improve elderly employment policies\",  # Welfare\n","        \"Garbage sorting is not done properly\",  # Environment\n","        \"Not enough playground facilities for children\",  # Welfare\n","        \"Taxi fares are too expensive\",  # Traffic\n","        \"Lack of parking spaces\",  # Traffic\n","    ],\n","    \"Category\": [\n","        \"Traffic\", \"Environment\", \"Welfare\", \"Traffic\", \"Environment\",\n","        \"Traffic\", \"Environment\", \"Welfare\", \"Traffic\", \"Traffic\",\n","        \"Environment\", \"Welfare\", \"Traffic\", \"Traffic\", \"Environment\",\n","        \"Welfare\", \"Environment\", \"Welfare\", \"Traffic\", \"Traffic\"\n","    ]\n","}\n","\n","# ë°ì´í„°í”„ë ˆì„ ìƒì„±\n","df = pd.DataFrame(data)\n","\n","# ğŸ“Œ 4. TF-IDF ë²¡í„°í™” (ì˜ì–´ ë°ì´í„° ë³€í™˜)\n","vectorizer = TfidfVectorizer()\n","X_vectorized = vectorizer.fit_transform(df[\"Complaint\"])\n","\n","# ğŸ“Œ 5. ë°ì´í„°ë¥¼ í•™ìŠµìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, df[\"Category\"], test_size=0.2, random_state=10)\n","\n","# ğŸ“Œ 6. ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ\n","model = LogisticRegression(max_iter=200)\n","model.fit(X_train, y_train)\n","\n","# ğŸ“Œ 7. ëª¨ë¸ í‰ê°€ (ì •í™•ë„ ì¸¡ì •)\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n","\n","# ğŸ“Œ 8. ìƒˆë¡œìš´ ë¯¼ì› ì˜ˆì¸¡í•˜ê¸°\n","new_complaints = [\"Taxi fares are too high\", \"There is garbage everywhere in the park\", \"Need more social welfare programs\"]\n","new_complaints_vectorized = vectorizer.transform(new_complaints)\n","predictions = model.predict(new_complaints_vectorized)\n","\n","# ğŸ“Œ 9. ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n","for complaint, pred in zip(new_complaints, predictions):\n","    print(f\"'{complaint}' â†’ Predicted category: {pred}\")\n"],"metadata":{"id":"23TeCrxm5uez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ğŸ“Œ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","!pip install scikit-learn pandas konlpy\n","\n","# ğŸ“Œ 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","from konlpy.tag import Okt\n","\n","# ğŸ“Œ 3. í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n","okt = Okt()\n","\n","def preprocess_korean_text(text):\n","    tokens = okt.morphs(text, stem=True)  # í˜•íƒœì†Œ ë¶„ì„ + ì–´ê°„ ì¶”ì¶œ\n","    stopwords = [\"ì—\", \"ê°€\", \"ì´\", \"ì€\", \"ëŠ”\", \"ì„\", \"ë¥¼\", \"ë„\", \"ë‹¤\", \"ì—ì„œ\", \"ìœ¼ë¡œ\", \"í•˜ê³ \", \"ë˜ë‹¤\"]  # ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì¤„ì´ê¸°\n","    return \" \".join([word for word in tokens if word not in stopwords])\n","\n","# ğŸ“Œ 4. ë°ì´í„°ì…‹ í™•ì¥ (ë°ì´í„° 50ê°œ ì´ìƒ ì¶”ê°€)\n","data = {\n","    \"ë¯¼ì› ë‚´ìš©\": [\n","        \"ë„ë¡œì— ê°€ë¡œë“±ì´ ê³ ì¥ë‚¬ì–´ìš”\", \"ì“°ë ˆê¸° ë¬´ë‹¨ íˆ¬ê¸° ì‹ ê³ í•©ë‹ˆë‹¤\", \"ë…¸ì¸ ë³µì§€ í˜œíƒì„ ëŠ˜ë ¤ì£¼ì„¸ìš”\",\n","        \"íš¡ë‹¨ë³´ë„ì— ì‹ í˜¸ë“±ì´ ê³ ì¥ë‚¬ì–´ìš”\", \"ê³µì›ì— ì“°ë ˆê¸°ê°€ ë§ì•„ìš”\", \"ë²„ìŠ¤ ë°°ì°¨ ê°„ê²©ì´ ë„ˆë¬´ ê¸¸ì–´ìš”\",\n","        \"ê³µì› ë‚˜ë¬´ê°€ ë„ˆë¬´ ë§ì•„ ì‹œì•¼ë¥¼ ê°€ë¦½ë‹ˆë‹¤\", \"ë³µì§€ê´€ í”„ë¡œê·¸ë¨ì„ í™•ëŒ€í•´ ì£¼ì„¸ìš”\",\n","        \"ë„ë¡œê°€ ë„ˆë¬´ ìš¸í‰ë¶ˆí‰í•´ì„œ ìš´ì „í•˜ê¸° í˜ë“¤ì–´ìš”\", \"ì§€í•˜ì² ì´ ë„ˆë¬´ ìì£¼ ê³ ì¥ë‚˜ìš”\",\n","        \"ê³µì›ì—ì„œ ë‹´ë°°ë¥¼ í”¼ìš°ëŠ” ì‚¬ëŒì´ ë§ì•„ìš”\", \"ë³´ìœ¡ ì‹œì„¤ì„ ë” ë§ì´ ë§Œë“¤ì–´ ì£¼ì„¸ìš”\",\n","        \"ì‹ í˜¸ë“±ì´ ë„ˆë¬´ ì§§ì•„ì„œ ê¸¸ì„ ê±´ë„ˆê¸° ì–´ë ¤ì›Œìš”\", \"ë²„ìŠ¤ ì •ë¥˜ì¥ì´ ë„ˆë¬´ ë©€ì–´ìš”\",\n","        \"í™˜ê²½ ë³´í˜¸ ì •ì±…ì„ ê°•í™”í•´ ì£¼ì„¸ìš”\", \"ë…¸ì¸ ì¼ìë¦¬ ì •ì±…ì„ ê°œì„ í•´ ì£¼ì„¸ìš”\",\n","        \"ì“°ë ˆê¸° ë¶„ë¦¬ìˆ˜ê±°ê°€ ì˜ ì•ˆ ë˜ê³  ìˆì–´ìš”\", \"ì•„ì´ë“¤ ë†€ì´í„° ì‹œì„¤ì´ ë¶€ì¡±í•´ìš”\",\n","        \"íƒì‹œ ìš”ê¸ˆì´ ë„ˆë¬´ ë¹„ì‹¸ìš”\", \"ì£¼ì°¨ ê³µê°„ì´ ë¶€ì¡±í•´ì„œ ë¶ˆí¸í•´ìš”\",\n","        \"ë„ë¡œ ì •ì²´ê°€ ì‹¬í•´ì„œ ì¶œê·¼ì´ ì–´ë µìŠµë‹ˆë‹¤\", \"ê³µì›ì˜ ë‚˜ë¬´ê°€ ë„ˆë¬´ ë§ì•„ì„œ ë²Œë ˆê°€ ë§ì´ ìƒê¹ë‹ˆë‹¤\",\n","        \"ì‚¬íšŒ ë³µì§€ ì„œë¹„ìŠ¤ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤\", \"êµì°¨ë¡œì—ì„œ ì‹ í˜¸ë“±ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤\",\n","        \"ê³µì‚¬ì¥ ë¨¼ì§€ê°€ ë„ˆë¬´ ë§ì•„ì„œ ìˆ¨ ì‰¬ê¸° ì–´ë µìŠµë‹ˆë‹¤\", \"ì¥ì• ì¸ì„ ìœ„í•œ ë³µì§€ì‹œì„¤ì„ ëŠ˜ë ¤ì£¼ì„¸ìš”\",\n","        \"ì§€í•˜ì²  ë…¸ì„ ì´ ë„ˆë¬´ ì ì–´ì„œ ì´ë™ì´ ë¶ˆí¸í•©ë‹ˆë‹¤\", \"í•™êµ ì£¼ë³€ì—ì„œ ì“°ë ˆê¸°ê°€ ë§ì´ ë²„ë ¤ì§€ê³  ìˆìŠµë‹ˆë‹¤\",\n","        \"ì–´ë¥´ì‹ ë“¤ì„ ìœ„í•œ ë¬´ë£Œ ì˜ë£Œ ì„œë¹„ìŠ¤ë¥¼ í™•ëŒ€í•´ì£¼ì„¸ìš”\", \"íƒì‹œ ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ë¶€ì¡±í•©ë‹ˆë‹¤\",\n","        \"ê³µì‚¬ì¥ ì†ŒìŒì´ ì‹¬í•´ì„œ ë°¤ì— ì ì„ ëª» ì¡ë‹ˆë‹¤\", \"ì–´ë¦°ì´ì§‘ì´ ë¶€ì¡±í•´ì„œ ëŒ€ê¸°ìê°€ ë„ˆë¬´ ë§ì•„ìš”\",\n","        \"ì£¼ì°¨ì¥ì´ ë„ˆë¬´ ë¶€ì¡±í•´ì„œ ë¶ˆë²• ì£¼ì°¨ê°€ ë§ìŠµë‹ˆë‹¤\", \"ë²„ìŠ¤ ìš”ê¸ˆì´ ë„ˆë¬´ ë¹„ìŒ‰ë‹ˆë‹¤\",\n","        \"ê³µì›ì˜ í™”ì¥ì‹¤ì´ ë„ˆë¬´ ë”ëŸ¬ì›Œìš”\", \"ì²­ì†Œë…„ì„ ìœ„í•œ ë¬¸í™”ì„¼í„°ë¥¼ ë” ë§Œë“¤ì–´ ì£¼ì„¸ìš”\",\n","        \"ì¶œí‡´ê·¼ ì‹œê°„ì— ë²„ìŠ¤ê°€ ë„ˆë¬´ ë¶ë¹•ë‹ˆë‹¤\", \"ì“°ë ˆê¸° ì²˜ë¦¬ì¥ì´ ë„ˆë¬´ ë©€ì–´ì„œ ë¶ˆí¸í•©ë‹ˆë‹¤\",\n","        \"ì¥ì• ì¸ì„ ìœ„í•œ ëŒ€ì¤‘êµí†µ ì‹œì„¤ì„ ê°œì„ í•´ ì£¼ì„¸ìš”\", \"ì „ê¸°ì°¨ ì¶©ì „ì†Œê°€ ë¶€ì¡±í•´ì„œ ë¶ˆí¸í•©ë‹ˆë‹¤\",\n","        \"ë„ì‹œê°€ìŠ¤ ìš”ê¸ˆì´ ë„ˆë¬´ ë¹„ìŒ‰ë‹ˆë‹¤\", \"ì‚°ì±…ë¡œì— ê°€ë¡œë“±ì´ ì—†ì–´ì„œ ìœ„í—˜í•©ë‹ˆë‹¤\",\n","        \"ë…¸ìˆ™ìë¥¼ ìœ„í•œ ì‰¼í„°ë¥¼ ë” ë§Œë“¤ì–´ ì£¼ì„¸ìš”\", \"ì§€í•˜ì²  í™˜ìŠ¹ ê±°ë¦¬ê°€ ë„ˆë¬´ ë©‰ë‹ˆë‹¤\",\n","        \"ì†ŒìŒ ê³µí•´ê°€ ë„ˆë¬´ ì‹¬í•©ë‹ˆë‹¤\", \"ìœ¡ì•„ íœ´ì§ ì •ì±…ì„ ë” ê°•í™”í•´ ì£¼ì„¸ìš”\",\n","        \"íƒë°° ë¶„ì‹¤ ë¬¸ì œê°€ ì‹¬ê°í•©ë‹ˆë‹¤\", \"í•™êµ ê¸‰ì‹ ì§ˆì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤\"\n","    ],\n","    \"ì¹´í…Œê³ ë¦¬\": [\n","        \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"í™˜ê²½\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\",\n","        \"êµí†µ\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\",\n","        \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"êµí†µ\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\",\n","        \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\",\n","        \"êµí†µ\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\",\n","        \"í™˜ê²½\", \"ë³µì§€\", \"êµí†µ\", \"í™˜ê²½\", \"ë³µì§€\", \"í™˜ê²½\", \"í™˜ê²½\", \"ë³µì§€\"\n","    ]\n","}\n","\n","# ğŸ“Œ 5. í˜•íƒœì†Œ ë¶„ì„ ì ìš©í•˜ì—¬ ë°ì´í„° ì „ì²˜ë¦¬\n","df = pd.DataFrame(data)\n","df[\"ë¯¼ì› ë‚´ìš©\"] = df[\"ë¯¼ì› ë‚´ìš©\"].apply(preprocess_korean_text)\n","\n","# ğŸ“Œ 6. TF-IDF ë²¡í„°í™” (Bigram ì ìš©)\n","vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # ë‹¨ì–´ 1~2ê°œ ì¡°í•©(Bigram) ì ìš©\n","X_vectorized = vectorizer.fit_transform(df[\"ë¯¼ì› ë‚´ìš©\"])\n","\n","# ğŸ“Œ 7. ë°ì´í„°ë¥¼ í•™ìŠµìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚˜ëˆ„ê¸°\n","X_train, X_test, y_train, y_test = train_test_split(X_vectorized, df[\"ì¹´í…Œê³ ë¦¬\"], test_size=0.2, random_state=10)\n","\n","# ğŸ“Œ 8. ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ\n","model = LogisticRegression(max_iter=300)\n","model.fit(X_train, y_train)\n","\n","# ğŸ“Œ 9. ëª¨ë¸ í‰ê°€ (ì •í™•ë„ ì¸¡ì •)\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"ëª¨ë¸ ì •í™•ë„: {accuracy * 100:.2f}%\")\n","\n","# ğŸ“Œ 10. ìƒˆë¡œìš´ ë¯¼ì› ì˜ˆì¸¡í•˜ê¸°\n","new_complaints = [\"íƒì‹œ ìš”ê¸ˆì´ ë„ˆë¬´ ë¹„ì‹¸ìš”.\", \"ê³µì›ì—ì„œ ë‹´ë°°ë¥¼ í”¼ìš°ëŠ” ì‚¬ëŒì´ ë§ì•„ìš”.\", \"ë³´ìœ¡ ì‹œì„¤ì„ ë” ë§ì´ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\"]\n","new_complaints = [preprocess_korean_text(text) for text in new_complaints]\n","new_complaints_vectorized = vectorizer.transform(new_complaints)\n","predictions = model.predict(new_complaints_vectorized)\n","\n","# ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n","for complaint, pred in zip(new_complaints, predictions):\n","    print(f\"'{complaint}' â†’ ì˜ˆì¸¡ ê²°ê³¼: {pred}\")\n"],"metadata":{"id":"gJAlT68S7sgQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ğŸ“Œ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# ğŸ“Œ 2. ë°ì´í„° ì¤€ë¹„ (ê³µë¶€ ì‹œê°„ vs í•©ê²© ì—¬ë¶€)\n","data = {\n","    \"ê³µë¶€ ì‹œê°„\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    \"í•©ê²© ì—¬ë¶€\": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]  # 5ì‹œê°„ ì´ìƒì´ë©´ í•©ê²©(1), ì•„ë‹ˆë©´ ë¶ˆí•©ê²©(0)\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# ğŸ“Œ 3. ì…ë ¥ ë°ì´í„°(X)ì™€ ì¶œë ¥ ë°ì´í„°(y) ì„¤ì •\n","X = df[[\"ê³µë¶€ ì‹œê°„\"]]  # ê³µë¶€ ì‹œê°„ì„ ì…ë ¥ ë³€ìˆ˜ë¡œ ì‚¬ìš©\n","y = df[\"í•©ê²© ì—¬ë¶€\"]  # í•©ê²© ì—¬ë¶€ê°€ ëª©í‘œ ê°’\n","\n","# ğŸ“Œ 4. í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‚˜ëˆ„ê¸°\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ğŸ“Œ 5. ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# ğŸ“Œ 6. ëª¨ë¸ ì˜ˆì¸¡ ë° ì •í™•ë„ í‰ê°€\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"ëª¨ë¸ ì •í™•ë„: {accuracy * 100:.2f}%\")\n","\n","# ğŸ“Œ 7. ìƒˆë¡œìš´ í•™ìƒì˜ ê³µë¶€ ì‹œê°„ì„ ì…ë ¥í•˜ë©´ í•©ê²© ì—¬ë¶€ ì˜ˆì¸¡í•˜ê¸° (DataFrame ì‚¬ìš©)\n","new_students = [[3], [6], [8]]  # ì˜ˆì¸¡í•  ìƒˆë¡œìš´ ë°ì´í„°\n","new_students_df = pd.DataFrame(new_students, columns=[\"ê³µë¶€ ì‹œê°„\"])  # í•™ìŠµ ë°ì´í„°ì™€ ê°™ì€ í˜•ì‹ ìœ ì§€\n","\n","# ğŸ“Œ 8. ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n","predictions = model.predict(new_students_df)\n","for study_time, result in zip(new_students, predictions):\n","    status = \"í•©ê²© âœ…\" if result == 1 else \"ë¶ˆí•©ê²© âŒ\"\n","    print(f\"ê³µë¶€ ì‹œê°„: {study_time[0]}ì‹œê°„ â†’ ì˜ˆì¸¡ ê²°ê³¼: {status}\")\n"],"metadata":{"id":"M5qoXqXHAn75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ì˜ˆì œ2)\të¡œì§€ìŠ¤í‹± íšŒê·€ë¡œ í•©ê²© ì˜ˆì¸¡í•˜ê¸°\n"],"metadata":{"id":"AReHGSYDzzqI"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n"],"metadata":{"id":"XpulV-aMz1pr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = {\n","    \"ê³µë¶€ ì‹œê°„\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    \"í•©ê²© ì—¬ë¶€\": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]  # 5ì‹œê°„ ì´ìƒì´ë©´ í•©ê²©(1)\n","}\n","df = pd.DataFrame(data)\n","df\n"],"metadata":{"id":"pojPgdvcz4Q-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ğŸ“Œ 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# ğŸ“Œ 2. ë°ì´í„° ì¤€ë¹„ (ê³µë¶€ ì‹œê°„ vs í•©ê²© ì—¬ë¶€)\n","data = {\n","    \"ê³µë¶€ ì‹œê°„\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n","    \"í•©ê²© ì—¬ë¶€\": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]  # 5ì‹œê°„ ì´ìƒì´ë©´ í•©ê²©(1), ì•„ë‹ˆë©´ ë¶ˆí•©ê²©(0)\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# ğŸ“Œ 3. ì…ë ¥ ë°ì´í„°(X)ì™€ ì¶œë ¥ ë°ì´í„°(y) ì„¤ì •\n","X = df[[\"ê³µë¶€ ì‹œê°„\"]]  # ê³µë¶€ ì‹œê°„ì„ ì…ë ¥ ë³€ìˆ˜ë¡œ ì‚¬ìš©\n","y = df[\"í•©ê²© ì—¬ë¶€\"]  # í•©ê²© ì—¬ë¶€ê°€ ëª©í‘œ ê°’\n","\n","# ğŸ“Œ 4. í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‚˜ëˆ„ê¸°\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ğŸ“Œ 5. ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# ğŸ“Œ 6. ëª¨ë¸ ì˜ˆì¸¡ ë° ì •í™•ë„ í‰ê°€\n","y_pred = model.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"ëª¨ë¸ ì •í™•ë„: {accuracy * 100:.2f}%\")\n","\n","# ğŸ“Œ 7. ìƒˆë¡œìš´ í•™ìƒì˜ ê³µë¶€ ì‹œê°„ì„ ì…ë ¥í•˜ë©´ í•©ê²© ì—¬ë¶€ ì˜ˆì¸¡í•˜ê¸° (DataFrame ì‚¬ìš©)\n","new_students = [[3], [6], [8]]  # ì˜ˆì¸¡í•  ìƒˆë¡œìš´ ë°ì´í„°\n","new_students_df = pd.DataFrame(new_students, columns=[\"ê³µë¶€ ì‹œê°„\"])  # í•™ìŠµ ë°ì´í„°ì™€ ê°™ì€ í˜•ì‹ ìœ ì§€\n","\n","# ğŸ“Œ 8. ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n","predictions = model.predict(new_students_df)\n","for study_time, result in zip(new_students, predictions):\n","    status = \"í•©ê²©\" if result == 1 else \"ë¶ˆí•©ê²©\"\n","    print(f\"ê³µë¶€ ì‹œê°„: {study_time[0]}ì‹œê°„ â†’ ì˜ˆì¸¡ ê²°ê³¼: {status}\")\n","\n"],"metadata":{"id":"T4IQB5Psz7xr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import euclidean_distances\n","\n","# ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸\n","sentences = [\n","    \"ë‚˜ëŠ” ì°¨ë¥¼ ì¢‹ì•„í•œë‹¤.\",\n","    \"ë‚˜ëŠ” ì»¤í”¼ë¥¼ ì¢‹ì•„í•œë‹¤.\"\n","]\n","\n","# TF-IDF ë²¡í„°í™”\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(sentences).toarray()  # ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜\n","\n","# ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°\n","distance = euclidean_distances([X[0]], [X[1]])[0][0]  # ë¬¸ì¥ 1 vs ë¬¸ì¥ 2\n","\n","# ê²°ê³¼ ì¶œë ¥\n","print(distance)\n"],"metadata":{"id":"F4l9N6I1Luzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UemuISasOkVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rjWI7gvSOWum"},"execution_count":null,"outputs":[]}]}